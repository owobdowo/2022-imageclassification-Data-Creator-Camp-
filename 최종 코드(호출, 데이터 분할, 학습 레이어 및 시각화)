{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuClass":"premium","mount_file_id":"1N1v18yuXxxUtUUWDnVt8J7-to4gJo_IT","authorship_tag":"ABX9TyMiwUKhWuem+dPV7bWIx/fN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","source":["# .from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"8C-EnID2q6mp","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"error","timestamp":1667027510977,"user_tz":-540,"elapsed":24,"user":{"displayName":"(컴퓨터정보공학부)이승연","userId":"17694348125977448674"}},"outputId":"62959d89-2eaf-4db2-91a2-85735ba8f2b7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-fddd3a0055a2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    .from google.colab import drive\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTOyBvsfmBBi"},"outputs":[],"source":["!unzip /content/drive/MyDrive/dataset/\"대학부 데이터셋.zip\" -d /content/L2_dataset"]},{"cell_type":"code","source":["# gpu쓰겠다는 코드\n","# device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"6bYTV55XqrF6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import cv2\n","import glob\n","import pathlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab.patches import cv2_imshow\n","# from torch.utils.data import Dataset\n","# from torchvision import datasets\n","# from torchvision.transforms import ToTensor\n","# from torch.utils.data import Dataset, DataLoader\n","# from torchvision import datasets, transforms\n","import tensorflow as tf\n","import sys\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential"],"metadata":{"id":"fG7KdfW1mGiM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''이거 하고 사진 최대값이랑...최소값출력해도 됨 근데 어차피 bgr255면 사진이라고 가정하는 마당에 이게 굳이 필요해?'''"],"metadata":{"id":"Keiwxcm_a7he","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1667027617427,"user_tz":-540,"elapsed":612,"user":{"displayName":"(컴퓨터정보공학부)이승연","userId":"17694348125977448674"}},"outputId":"72692182-9088-4e38-d019-6ddd9544809e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'이거 하고 사진 최대값이랑...최소값출력해도 됨 근데 어차피 bgr255면 사진이라고 가정하는 마당에 이게 굳이 필요해?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"ZY4X9AVydCpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sd4r2y7N9kNA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#그래서 [0,0]값이 255가 아닐 경우 제거하는 메소드...간헌대\n","file_path = '/content/L2_dataset'\n","list_class= glob.glob(file_path + '/*')\n","for i  in list_class:\n","  list_images= glob.glob(i + '/*')\n","  for j in list_images:\n","    img = cv2.imread(j,cv2.IMREAD_UNCHANGED)\n","    #jpg\n","\n","    if len(img[0,0].shape)==3:\n","      b,g,r=img[0,0]\n","    #png\n","    elif len(img[0,0].shape)==4:\n","      b,g,r,a=img[0,0]\n","\n","    if b!=255 or g!=255 or r!=255 and a!=0:#배경이 흰색이 아니고 투명화된 것도 아닐 경우\n","      os.remove(j)"],"metadata":{"id":"ufI9DInmR6e-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b,g,r=img[0,0]\n","len(img[0,0].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XXbBzcfnPmL","executionInfo":{"status":"ok","timestamp":1667028131219,"user_tz":-540,"elapsed":4,"user":{"displayName":"(컴퓨터정보공학부)이승연","userId":"17694348125977448674"}},"outputId":"26aa6a1b-0c4f-49a3-e93b-f35c6a54730a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["255"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[" ##이미지 불균형\n"," # image generator 생성\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","\n","datagen = ImageDataGenerator(\n","        rotation_range=90,      # 회전\n","        width_shift_range=0.2,  # 수평 방향 이동\n","        height_shift_range=0.2, # 수직 방향 이동\n","        brightness_range=(0.3, 0.7),    # 밝기\n","        zoom_range=(0.5, 1.5),         # 확대\n","        horizontal_flip=True,   # 수평방향(가로) 뒤집기\n","        fill_mode='nearest'     # 수직방향(세로) 뒤집기\n","       )\n","\n","i = 0\n","for batch in datagen.flow_from_directory('/content/drive/MyDrive/Dataset', classes=['L2_52'], batch_size=32, color_mode='rgb', target_size=(255, 255), save_to_dir='/content/drive/MyDrive/Dataset/L2_52'):\n","    i += 1\n","    if i == 19:\n","        break\n","# 증강된 데이터 배치 생성\n","# generator = datagen.flow_from_directory('/content/drive/MyDrive/Dataset', target_size=(255,255), batch_size=32,  classes=['L2_3'], save_to_dir = '/content/drive/MyDrive/Dataset/L2_3')"],"metadata":{"id":"Egvq_nEIop_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 파일 경로 가져오기\n","file_path1 = '/content/L2_dataset/L2_3'\n","file_path2 = '/content/L2_dataset/L2_10'\n","file_path3 = '/content/L2_dataset/L2_12'\n","file_path4 = '/content/L2_dataset/L2_15'\n","file_path5 = '/content/L2_datasett/L2_20'\n","file_path6 = '/content/L2_dataset/L2_21'\n","file_path7 = '/content/L2_dataset/L2_24'\n","file_path8 = '/content/L2_dataset/L2_25'\n","file_path9 = '/content/L2_dataset/L2_27'\n","file_path10 = '/content/L2_dataset/L2_30'\n","file_path11 = '/content/L2_dataset/L2_33'\n","file_path12 = '/content/L2_dataset/L2_34'\n","file_path13 = '/content/L2_dataset/L2_39'\n","file_path14 = '/content/L2_dataset/L2_40'\n","file_path15 = '/content/L2_dataset/L2_41'\n","file_path16 = '/content/L2_dataset/L2_44'\n","file_path17 = '/content/L2_dataset/L2_45'\n","file_path18 = '/content/L2_dataset/L2_46'\n","file_path19 = '/content/L2_dataset/L2_50'\n","file_path20 = '/content/L2_dataset/L2_52'\n","\n","# 파일 경로 리스트로 저장\n","list_images1 = glob.glob(file_path1 + '/*')\n","list_images2 = glob.glob(file_path2 + '/*')\n","list_images3 = glob.glob(file_path3 + '/*')\n","list_images4 = glob.glob(file_path4 + '/*')\n","list_images5 = glob.glob(file_path5 + '/*')\n","list_images6 = glob.glob(file_path6 + '/*')\n","list_images7 = glob.glob(file_path7 + '/*')\n","list_images8 = glob.glob(file_path8 + '/*')\n","list_images9 = glob.glob(file_path9 + '/*')\n","list_images10 = glob.glob(file_path10 + '/*')\n","list_images11 = glob.glob(file_path11 + '/*')\n","list_images12 = glob.glob(file_path12 + '/*')\n","list_images13 = glob.glob(file_path13 + '/*')\n","list_images14 = glob.glob(file_path14 + '/*')\n","list_images15 = glob.glob(file_path15 + '/*')\n","list_images16 = glob.glob(file_path16 + '/*')\n","list_images17 = glob.glob(file_path17 + '/*')\n","list_images18 = glob.glob(file_path18 + '/*')\n","list_images19 = glob.glob(file_path19 + '/*')\n","list_images20 = glob.glob(file_path20 + '/*')\n","\n","l1 = len(list_images1)\n","l2 = len(list_images2)\n","l3 = len(list_images3)\n","l4 = len(list_images4)\n","l5 = len(list_images5)\n","l6 = len(list_images6)\n","l7 = len(list_images7)\n","l8 = len(list_images8)\n","l9 = len(list_images9)\n","l10 = len(list_images10)\n","l11 = len(list_images11)\n","l12 = len(list_images12)\n","l13 = len(list_images13)\n","l14 = len(list_images14)\n","l15 = len(list_images15)\n","l16 = len(list_images16)\n","l17 = len(list_images17)\n","l18 = len(list_images18)\n","l19 = len(list_images19)\n","l20 = len(list_images20)\n","\n","df = pd.DataFrame({\n","    'class ID' : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n","    'class': ['L2_3', 'L2_10', 'L2_12', 'L2_15', 'L2_20', 'L2_21', 'L2_24', 'L2_25', 'L2_27', 'L2_30', 'L2_33', 'L2_34', 'L2_39', 'L2_40', 'L2_41', 'L2_44', 'L2_45', 'L2_46', 'L2_50', 'L2_52'],\n","    'value': [l1, l2, l3, l4, l5, l6, l7, l8, l9, l10, l11, l12, l13, l14, l15, l16, l17, l18, l19, l20],\n","    'filepath': [file_path1,file_path2,file_path3,file_path4,file_path5,file_path6,file_path7,file_path8, file_path9, file_path10, file_path11, file_path12, file_path13, file_path14, file_path15, file_path16, file_path17, file_path18, file_path19, file_path20]\n","    })"],"metadata":{"id":"qCLcHFH43KCY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##파일 개수 시각화\n","x=df['class'].to_list()\t\t\t#df(데이터 프레임)의 class를 리스트로 저장\n","y=df['value'].to_list()\t\t\t#df(테이터 프레임)의 value 필드를 리스트로 저장\n","\n","plt.figure(figsize=(15, 8))\t\t\t#그래프 크기 지정\n","plt.xlabel('class')\t\t\t\t#그래프 x축 이름(label) 지정\n","plt.ylabel('Value')\t\t\t\t#그래프 y축 이름(label) 지정\n","\n","plt.bar(x, y, width=0.6, color='orange')\t#리스트로 저장한 x와 y로 막대(bar) 그래프 플롯"],"metadata":{"id":"ej-l96J53KN7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","for batch in datagen.flow_from_directory('/content/drive/MyDrive/Dataset', classes=['L2_3'], batch_size=32, color_mode='rgb', target_size=(255, 255), save_to_dir='/content/drive/MyDrive/Dataset/L2_3'):\n","    i += 1\n","    if i == 13:\n","        break"],"metadata":{"id":"96yf2vnc3SSV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","file_path = pathlib.Path('/content/L2_dataset')\n","class_path=list(file_path.glob('*'))\n","image_path = list(file_path.glob('*/*'))\n","#사진리스트에 들어갔는지 확인\n","print(image_path[:10])\n","class_path"],"metadata":{"id":"Rd_BdBPbWN7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터셋 사이즈\n","batch_size = 32\n","img_height = 255\n","img_width = 255\n","\n","#분할\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  file_path,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"9rsH7HwCYotU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train,val로 나눔\n","val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  file_path,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"iZHCX1EZgp_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names = train_ds.class_names\n","print(class_names)"],"metadata":{"id":"93ePS0xpgunX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_batch, labels_batch in train_ds:\n","  print(image_batch.shape)\n","  print(labels_batch.shape)\n","  break"],"metadata":{"id":"5bUc0RKFg5PW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터 러닝시 성능 향상을 위한 코드...\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"u6cJ8WyshC71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#0~255to0~1\n","normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"],"metadata":{"id":"aw5CX0CmhGNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n","image_batch, labels_batch = next(iter(normalized_ds))\n","first_image = image_batch[0]\n","# Notice the pixels values are now in `[0,1]`.\n","print(np.min(first_image), np.max(first_image))"],"metadata":{"id":"XJ-9qx6Kh0U6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["분류 레이어\n"],"metadata":{"id":"1-2hWKagIbOE"}},{"cell_type":"code","source":["num_classes = 20\n","#convolutional model.........\n","model = Sequential([\n","  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(num_classes)\n","])"],"metadata":{"id":"rJMfNre9h32j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.\n","\n","(optimizer='adam',#최적화 알고리즘='adam' , 손실계산\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"metadata":{"id":"_KWnbwB6iAbb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"_bOjNeJmiCZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 훈련\n","epochs=10#under or over 조절\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")\n","#반복시행하면서 정확도가 늘어야하는데 늘지 않음, 초기값도 지나치게 낮음 전처리문젠가?"],"metadata":{"id":"gkKyEx6BiD6x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#훈련결과 시각화\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"id":"NBAZO8tqiIkh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#분류 이미지 증강orconv layer 수정"],"metadata":{"id":"HNNbQb6vnkQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","##Pytorch코드, ImageFolders오류가 있어서 우선 Tensorflow사용"],"metadata":{"id":"Y0Z1MOQQiNHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install split-folders tqdm"],"metadata":{"id":"4ZZiIdBmmHJb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #train/test 데이터 파일 분할\n","\n","# import splitfolders\n","# splitfolders.ratio('/content/L2_dataset', output=\"/content/L2_dataset_div\", seed=77, ratio=(.8, 0.2))"],"metadata":{"id":"9xeKUb2BmHL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# base_dir='/content/L2_dataset_div'\n","# train_dir = '/content/L2_dataset_div/train'\n","# val_dir='/content/L2_dataset_div/val'\n","# # 클래스 경로 리스트로 저장\n","# list_class_t= glob.glob(train_dir + '/*')\n","# list_images_t= glob.glob(list_class_t[0] + '/*')\n","\n","# # 클래스 개수 확인\n","# # len(list_class_t)\n","# # list_class_t[0]\n","\n","\n","\n"],"metadata":{"id":"ePM5R3Js-x8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #train 배열에 각 파일 넣어줌... 넣는 값이 하나가 아니니 이차원 배열으로 설정\n","# train_list=[[]]*len(list_class_t)\n","# for i in range(len(list_class_t)) :\n","#   train_list[i]=os.listdir(list_class_t[i])\n","#   train_list[i].sort()\n","# #확인\n","# # train_list[1][:10]"],"metadata":{"id":"Vcn-QvucLh_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data_transforms = {\n","#     'train':transforms.Compose([\n","#         transforms.RandomResizedCrop(224),\n","#         transforms.RandomHorizontalFlip(),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","#          ]),\n","#     'val':transforms.Compose([\n","#         transforms.Resize(256),\n","#         transforms.CenterCrop(224),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","#     ]),\n","# }\n","# train_transforms=transforms.Compose([\n","#         transforms.RandomResizedCrop(224),\n","#         transforms.RandomHorizontalFlip(),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","#          ])\n","# val_transforms=transforms.Compose([\n","#         transforms.Resize(256),\n","#         transforms.CenterCrop(224),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","#     ])"],"metadata":{"id":"5IgSu4nzLiDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# image_datasets={x:datasets.ImageFolder(os.path.join(base_dir,x),transform=data_transforms[x])\n","#    for x in ['train','val']}\n","\n","\n","# image_dataloaders={x:torch.utils.data.DataLoader(image_datasets[x],batch_size=4, shuffle=True,num_workers=5)\n","#    for x in ['train','val']}\n","\n","# dataset_sizes = {x: len(image_datasets[x]) for x in['train','val']}\n","# class_names=image_datasets['train'].classes\n","\n","# #위에 정의된 접근 권한에서 ImageFolder에 접근할 권한이 없다는 것같은데...왜이래?..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"id":"B-EgGN-8LiF3","executionInfo":{"status":"error","timestamp":1666808271150,"user_tz":-540,"elapsed":305,"user":{"displayName":"(컴퓨터정보공학부)이승연","userId":"17694348125977448674"}},"outputId":"3f6f5ad8-b653-41a2-9c17-374da6d69816"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-107-b95b68debbc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m image_datasets={x:datasets.ImageFolder(os.path.join(base_dir,x),transform=data_transforms[x])\n\u001b[0;32m----> 2\u001b[0;31m    for x in ['train','val']}\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m image_dataloaders={x:torch.utils.data.DataLoader(image_datasets[x],batch_size=4, shuffle=True,num_workers=5)\n","\u001b[0;32m<ipython-input-107-b95b68debbc5>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m image_datasets={x:datasets.ImageFolder(os.path.join(base_dir,x),transform=data_transforms[x])\n\u001b[0;32m----> 2\u001b[0;31m    for x in ['train','val']}\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m image_dataloaders={x:torch.utils.data.DataLoader(image_datasets[x],batch_size=4, shuffle=True,num_workers=5)\n","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'ImageFolder'"]}]},{"cell_type":"code","source":["# train_dataset=datasets.ImageFolder(root=train_dir,transform=train_transforms)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"y1_yTQJ3g80M","executionInfo":{"status":"error","timestamp":1666808658671,"user_tz":-540,"elapsed":323,"user":{"displayName":"(컴퓨터정보공학부)이승연","userId":"17694348125977448674"}},"outputId":"8313b628-286e-44da-9eb6-08b500b4c604"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-110-549a29b68ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'ImageFolder'"]}]},{"cell_type":"code","source":["# for i ,(img, label) in enumerate(dataloaders['train']):\n","#   print(img.shape)\n","#   print(label)\n"],"metadata":{"id":"_OgozNBG2-nm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# #GPU로 돌리기 위해 device에 gpu연결\n","# device\n","# #데이터로더 시각화\n","# def imshow(inp,title=None):\n","\n","#   inp = inp.numpy().transpose((1,2,0))\n","#   mean=np.aray([0.485,0.456,0.406])\n","#   std=np.array([0.229,0.224,0.225])\n","#   inp=std*inp+mean\n","#   inp=np.clip(inp,0,1)\n","#   plt.imshow(inp)\n","#   if title is not None:\n","#     plt.iltle(title)\\\n","#   plt.pause(0.001)\n","\n","#   inputs,classes=next(iter(dateloaders['train']))\n","\n","#   out=torchvision.utils.make_grid(inputs)\n","#   imshow(out,title=[class_names[x] for x in classes])"],"metadata":{"id":"uskv9Q_vyr2y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def train_model(model,optimizer,criterion,schedular,num_epochs=25):\n","#   since=time.time()\n","#   best_model_wts=copy.deepcopy(model.state_dict())\n","#   best_acc=0.0\n","\n","#   for epochs in range(num_epochs):\n","#     print('EPOCH {}/{}'.format(epochs, num_epochs-1))\n","#     for phase in ['train','validation']:\n","#       if phase =='train':\n","#         model.train()\n","#       else :\n","#         model.eval()\n","\n","#       running_lose=0.0\n","#       runnung_correts=0\\\n","\n","#       for i,(inputs,labels)in enumerate(dataloaders[phase]):\n","#         oprimizer.zero_grad()\n","#         #GPU에서 돌아가게\n","#         inputs = inputs.to(device)\n","#         labels=labels.to(device)\n","\n","#         with torch.set_grad_enabled(phase=='train'):\n","#           outputs = model(inputs)\n","#           _, preds = torch.max(outputs, 1)\n","#           loss - criterion(outputs, labels)\n","\n","#           if pahase=='train':\n","#             loss.backward()\n","#             optimizer.step()\n","#         running_loss += loss.item()*inputs.size(0)\n","#         running_corrects +=torch.sum(preds==labels.data)\n","#       if phase =='train':\n","#         schedular.step()\n","\n","#       epoch_loss=running_loss/dataset_sizes[phase]\n","#       epoch_acc = rinning_corrects.double()/dataset_sizes{phase}\n","\n","#       print('{}Loss: {:.4f} ACC: {:.4f}'.format(phase, epoch_loss, epoch_loss))\n","\n","#       if phase == 'validation' and epoch)acc>best_acc:\n","#         best_acc=epoch_acc\n","#         best_model_wts= copy.deepcopy(model.state_dicet())\n","#     print()\n","#   time_elapsed = time.time() - since\n","#   print('training complete in P;.0f}m {:.0f}s'.format(\n","#       time elapsed // 60, time_elapsed%60))\n","#   print('best val Acc:{:4f}'.format(best_acc))\n","\n","#   model.load_state_dict(best_model_wts)\n","#   return model\n","\n"],"metadata":{"id":"iLYFZGUTmHT-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def visualize_model(model, num_images=6):\n","#   was_training=model.training\n","#   model.eval()\n","#   images_so_far=0\n","#   fig=plt.figure()\n","\n","#   with torch.no_grad():\n","#     for i,(inputs,labels)in enumerate(dataloades['validation']):\n","#       inputs= inputs.to(device)\n","#       labels=labels.to(device)\n","\n","#       outputs = model(inputs)\n","#       _, preds = torch.max(outputs,1)\n","\n","#       for j in range(inputs.size()[0]):\n","#         images_so_fra +=1\n","#         ax=plt.subplot(num_images//2, 2, images_so_far)\n","#         ax.axis('off')\n","#         ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n","#         imshow(inputs.cpu().data[j])\n","\n","#         if images_so_far ++ num_images:\n","#           model.train(mode=was_training)\n","#           return\n","#     model.train(mode=was_training)"],"metadata":{"id":"48qB6qSRmHZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = torchvision.models.vgg16(pretrained=True)\n","# for param in model.parameters():\n","#   param.requires_grad=True\n","\n","# model.classifier._modules['6']=nn.Linear(4096,2)\n","# parameters = model.classifier._modules['6'].parameters()\n","# model = model.to(device)"],"metadata":{"id":"RpDGaOfg4z7L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#전체 파일 픽셀 평균\n","file_path = '/content/L2_dataset'\n","list_class= glob.glob(file_path + '/*')\n","for i  in range(len(list_class)):\n","  hsum=0\n","  wsum=0\n","  file_path=list_class[i]\n","  list_images= glob.glob(file_path + '/*')\n","  for j in range(len(list_images)):\n","\n","    img = cv2.imread(list_images[j])\n","    h,w,c=img.shape\n","    hsum+=h\n","  print(list_class[i])\n","  print(\"hsum=\",hsum,\"file_num\",len(list_images))\n","  print(hsum/len(list_images))\n","  count.append(hsum/len(list_images))\n","\n"],"metadata":{"id":"0tcRFSERd6O2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #loss\n","# criterion = nn.CrossEntropyLoss()\n","\n","# oprimizer = oprim.Adam(parameters, Ir=0.001)\n","\n","\n","# exp_Ir_scheduler = Ir_scheduler.StepLR(optimizer,step_size=7,gamma=0.1)\n","\n","# model= train_model(model,optimizer,criterion,exp_Ir_scheduler, num_epochs=5)\n","\n","# visualize_model(model)\n","\n","# plt.ioff()\n","# plt.show()"],"metadata":{"id":"ZUnI-EKw5P_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #실사와 그림간의 픽셀평균 차이\n","# file_path = '/content/L2_dataset'\n","# list_class= glob.glob(file_path + '/*')\n","# for i  in range(len(list_class)):\n","#   hsum=0\n","#   wsum=0\n","#   hsum_r=0\n","#   wsum_r=0\n","#   art_num=0\n","#   real_num=0\n","#   arth_min=list_images[0].shape #가장 첫번째 사진 크기 저장\n","#   realh_max=list_images[0].shape#후에 real,arth최대 최소값 저장에 쓰임\n","#   file_path=list_class[i]\n","#   list_images= glob.glob(file_path + '/*')\n","#   for j in range(len(list_images)):\n","\n","#     img = cv2.imread(list_images[j])\n","#     b,g,r=img[0,0]\n","#     h,w,c=img.shape\n","\n","#     if b==255 and g==255 and r==255:\n","#       hsum+=h\n","#       art_num=art_num+1\n","#       if arth_min>h:\n","#         arth_min=h\n","#     else:\n","#       hsum_r+=h\n","#       real_num=real_num+1\n","#       if realh_max<h:\n","#         realh_max=h\n","\n","#   print(list_class[i])\n","#   print(\"art avg=\",hsum/art_num)\n","#   if(real_num!=0):\n","#     print(\" real avg=\",hsum_r/real_num)\n","#   else:\n","#     print(\"실사추정 이미지 없음\")\n","#   print(\"일러스트 픽셀 최소값\",arth_min,\"사진 픽셀 최대값\",realh_max)\n","#   #이러면 사진 크기 기준으로 사진 나눌때 할 수 있음....\n","\n"],"metadata":{"id":"rY2TWuUVY2S4"},"execution_count":null,"outputs":[]}]}